\section{Design}\label{sec:design}

\mtjnote{SWEBOOK \enquote{Design for security is concerned with how to prevent unauthorized disclosure, creation, change, deletion, or denial of access to information and other resources. It is also concerned with how to tolerate security-related attacks or violations by limiting damage, continuing service, speeding repair and recovery, and failing and recovering securely. Access control is a fundamental concept of security, and one should also ensure the proper use of cryptology.}}

We design a beacon to both meet the previously stated requirements, and to prevent as many of the threats identified and categorized in the STRIDE analysis. We want the beacon to be as secure as possible while still being practically viable, so we will also consider the usability and scalability of the beacon.

To meet the requirement of extendability, we use a \gls{soa} to design the beacon.
This architecture splits systems into application components, also called services.
These services serve a single purpose, i.e.\ they each logically represent part of the activity needed for the entire system and have a specified outcome.
Communication between components is done according to a well-defined protocol, such that no one component is reliant on the inner workings of another;
a component, or service, should be seen as a self-contained black box.

This architecture provides loose coupling in the system and also allows for easier fault tolerance since services, being a black box, are easily replaceable on failure.
However, as services need knowledge about other relevant services, some mechanism for service discovery is typically deployed.
This can be a single point of failure, but mitigated by using redundancy \cite{soa_redundancy}.
\fxnote{expand on this and how it can be decentralized}

\subsection{Components of a Beacon}
\label{sub:components_of_a_beacon}
In the \gls{soa}, a single instance of a randomness beacon will consist of the following (see \cref{fig:beacon_arch}):
\begin{description}
    \item[A number of input collector services] which can collect from a myriad of different sources.
    \item[An input processing service] which aggregates the input from all the collectors.
    \item[A computation service] which commits to the aggregated input, runs the computation to generate an output.
    \item[A number of publishing services] which can publish the commitment, output, and any relevant proofs, to different outlets.
\end{description}

\subimport{}{beacon_architecture.tex}

\subsection{Pipeline}%
\label{sub:pipeline}
In our \gls{soa}, data only flows one way through the system, and each component performs an independent transformation.
This effectively means that a beacon is a pipeline where data flows into the system as inputs, is processed, transformed to a random output, and lastly published.

The pipeline architecture can be seen as a specialization of the \gls{soa} pattern, since each step in the pipeline is a service as defined in a \gls{soa}.
When considering the system as a pipeline some restrictions are imposed compared to the more generic \gls{soa}, in that data only flows in one direction.

%The pipeline also allows for parallel operation, i.e.\ input collectors can run continuously as can the computation service.
%This effectively means that we can reach the highest possible output of randomness given a single computation service.
%One might argue that several computation services slightly offset in start time could output more frequently, but this would by our design be considered several different beacons.
Parallelizing a pipeline to increase the output frequency is also possible. We will discuss this topic later.

In some scenarios a beacon may consist of multiple computation services as a mean of redundancy, as long as each computation is run on the same input.
The same can be said about input processors, where a beacon may need redundancy to likewise avoid a single point of failure.
This brings forth the issue of consensus about which input to use\msmnote{out of scope or explain solutions?}.

\subsection{Security Design}

From a security perspective, new attack surfaces are introduced by splitting up the system from a monolithic self-contained architecture to a service-oriented kind.
When designing a composable system such as our randomness beacon it is important to take the inter-component communication into account.
For example, this architecture can potentially make it possible for adversaries to block out parts of the system, by means of \gls{dos} attacks.
Moreover, the protocol used to communicate from service to service must be secure in a way that prevents adversaries from being able to undetectably manipulate the messages.

In the case of a randomness beacon, the security also embodies the operator's ability to predict or manipulate the output.
This means we need some mechanism to prevent the operator from performing last-draw attacks disguised as regular user inputs, or excluding certain inputs to alter the output.
Moreover, we also want to prevent the operator from being able to initiate multiple beacon computations, and then only publish the output which benefits the operator the most.

Generally, these concerns can be mitigated by enforcing a \gls{cco} workflow in the beacon protocol.
This effectively means that each published output is paired with a commitment which can be used in the verification of the beacon.
The operator must publish the commitment a significant amount of time before the output is published --- otherwise, the beacon operator could just publish a commitment to any desired output. Furthermore, the operator is limited to a single commitment --- otherwise the operator could publish several commitments and only publish the most desireable output.

The commitment consists of the hashes of the inputs to the beacon, structured in a Merkle tree, the root of which is inputted to the delay function. This allows any other party to compute the randomness alongside the beacon operator. It also ensures that the operator can not withhold any numbers, and effectively reduces the \enquote{market value} of the output, making it less attractive to sell early access to it.

To guarantee that the time between publishing the commitment and output has been spent on computing the output, we utilize a \emph{delay function}.
Delay functions require a given amount of time to run and are inherently sequential, meaning that they cannot benefit from parallel execution.
When deploying delay functions in randomness beacons it is important to keep verification in mind.
A user should be able to run the delay function in reverse to confirm that a commitment matches the output.
To avoid having to require each user to execute the full delay function, we use a flavour of delay functions which are asymmetrically hard, i.e.\ hard to compute but easy to verify.

The delay function also partially protects against last-draw attacks by adversaries. A last-draw attack would attempt to bias the output by crafting an input so as to produce favorable randomness. The adversary needs to compute the result of adding a specific input as the last input. Delay functions make this significantly more difficult to attempt due to the time needed to compute the result.
Given a delay function that takes five minutes to complete, an adversary must dedicate five minutes of processor time to any given input he attempts to use. This means he must dedicate large amounts of resources to perform any significant amount of attempts, and more importantly: if a single input is added to the beacon within that five minute period, all of his work will be null, and he will be forced to restart.

The combination of these concepts, \gls{cco} and a delay function, effectively gives the following workflow for each cycle of the beacon: First, it collects inputs and processes them. Then, it publishes a commitment containing all inputs, before beginning the computation. When the computation is finished, it publishes the output.

\subimport{}{trust.tex}
\subimport{}{hash_functions.tex}
