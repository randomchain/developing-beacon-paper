\subsection{Probabilistic Trust}%
\label{sub:probabilistic_trust}
In our approach to a randomness beacon we want to push beyond the need for honest operators, and na√Øve users.
To achieve this we first need to quantify trusting the beacon and then determine thresholds for reasonable behavior.
This effectively will provide a measure of probabilistic trust, where users much decide for themselves if the probability of honest operation is adequate.

We present a property which, if satisfied, says that the user can trust that the beacon operator is not capable of fooling them.
The property is true if the user determines that nobody will be able to compute the delay function in the time between they sent their input and received the commitment.
This can be condensed to:
\begin{equation*}
    t_\text{COMMITMENT} - t_\text{INPUT} < T_\text{DELAY FUNCTION}
\end{equation*}
given that $t_\text{INPUT}$ is the time when the user sent the input, $t_\text{COMMITMENT}$ is when the user received the commitment, and $T_\text{DELAY FUNCTION}$ is the fastest computation of the delay function.
This tells us that for users to be more likely to trust a beacon, the time between them sending their input and receiving the commitment must be significantly smaller than the time between the commitment and the output.
In fact, it must be smaller than the shortest time a given user thinks the operator could be able to compute the delay function.

Taking this into consideration we present a beacon operation protocol which can be adjusted to increase or decrease this limit.
The operation must be sequential which means that we must collect input before computing the delay function.
However, because we want to spend more time computing than we are collecting input, a strictly sequential beacon will contain dead spots where no user is submitting input.
This may be acceptable in some scenarios, but we want to design a beacon which always accepts inputs and which will not be suspected of malicious operation.
To achieve this we parallelize the beacon protocol, meaning that several delay functions will run in parallel but offset in time and using different input.

In~\cref{fig:beacon_parallel_timeline} this is illustrated, where these offset but parallel beacons are seen.
We observe that no input collection is run in parallel nor overlapping, which resembles a constant stream of input collection.
Moreover, the computation components can eventually be reused for future beacon computations, thereby eliminating the need for spinning up new computation services.
These observations are depicted in \cref{fig:beacon_parallel_timeline_real}, where the beacon would output at each circle shown in the diagram.

\subimport{}{timeline_diagrams.tex}

