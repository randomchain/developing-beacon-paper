\section{Introduction}
\emph{Randomness beacons}, services emitting unpredictable random values at fixed intervals, have been around for a long time.
In 1983 Michael O.\ Rabin coined the term and used one to add probabilistic security in several protocols~\cite{rabin1983transaction}.
In this definition, a randomness beacon was to be seen as an impartial third-party trusted to be unbiased towards any outcome.
As such, Rabin's beacon is to be \emph{trusted}, i.e.\ you should trust the beacon operator (the entity running the beacon service) to not be biased because you cannot verify that they are unbiased.

For quite a while, randomness beacons did not receive much attention, probably because alternatives to Rabin's protocols not requiring a trusted beacon were used instead (such as~\cite{BGMR}).
Circa 2010 a renewed interest in beacons was seen as an increase in beacon-related literature, and the trend in this new literature was to remedy the need to trust the beacon operator.
We believe it may have been a reaction to revelations like the NSA whistle-blower leaks that diminished people's trust in authorities.
In other words, people had their eyes opened to the fact that \emph{trust} can be an issue in itself and that removing the need for trust in any one entity could, in some cases, be beneficial.
As an example, cryptocurrencies have flourished in recent years alongside a sharp rise in the popularity of blockchains --- two technologies seeking to facilitate cooperation of mutually distrustful users.

Conceptually, randomness beacons seem to fit this environment of minimizing the need to trust as a randomness beacon is acting as an impartial party.
However, the \enquote{old} way, requiring users to trust the operator, simply shifts the trust issue to the centralized entity, i.e.\ the beacon operator.
If anyone uses a randomness beacon, it is often specifically because they do not wish to trust anyone.
Therefore, we believe trusting the randomness beacon is a moot point, especially since the recent literature presents several ways of avoiding it.
%The body of this work will be to discuss, design, and implement a beacon following the concept of not requiring users to trust it.% Before doing so, let's take a small detour and talk about potential use cases and the motivation for using a beacon at all.

Even though the literature theoretically argues for a particular solution, we have not seen many implementation of them. There is a bridge from theoretical solution to an actual running beacon, and we believe this bridge is uncharted territory. The literature only lightly touches the subject. We want to touch this subject, and find out which implications appear underway.

\subsection{Terminology}
In this work, we will use the terms \enquote{randomness beacon} and \enquote{beacon} interchangeably. %, and make no initial assumptions on the properties of a beacon.
As discussed, we see two distinct groups of randomness beacons: the ones requiring users to blindly trust the beacon operator (Ã  la Rabin's original beacon) --- we will refer to these as \emph{trust-requiring} beacons; and the \enquote{new generation} randomness beacons of recent literature, which convincingly prove to all users of the beacon that nothing dubious happened during the creation of the random output --- we will refer to these as \emph{trust-minimizing} beacons.

%In this work, we will use the terms \enquote{randomness beacon} and \enquote{beacon} interchangeably, and make no initial assumptions on the properties of a beacon. We also use \enquote{trust-requiring} and \enquote{trust minimizing} to refer to the generations of beacons.

\subsection{Security Goals}\label{sec:security_goals}
Requiring users to trust the beacon operation does not solve the issue in the majority of cases --- it simply shifts the issue. A beacon that does not require trust of users is more general and will support a wider array of use cases.

Therefore, we design and implement a beacon for a hostile world-view described as follows:
\enquote{Everybody, including the beacon operator, may be secretly colluding against you and willing to put an unlimited amount of money and resources towards manipulating or biasing the process for their own benefit}.

The intent is for the beacon to be usable under the assumption that everyone colludes against the user.

\subsection{Use Cases}
In order to motivate the usefulness and value of a randomness beacon we present a series of use cases. Further, we present some use cases we have seen mentioned in various literature, but we do not find quite as good. This demonstrates the curious conditions under which a randomness beacon fits as a solution.

The fundamental use case of a beacon is to generate randomness that multiple parties can agree is not biased to anyone's advantage or disadvantage.

\subsubsection{Sampling}
A classic use for randomness is sampling, however most cases of sampling are performed in environments with some levels of trust.
In such cases, a beacon would not be needed, but there are some where it would.
For election recounts, the competing parties would have a large interest in ensuring the results are not biased against them in any way.
There has also previously been controversy surrounding such recounts, such as the American presidential election in 2000~\cite{bushgore}.

The high stakes and public nature makes a transparent and unbiased source of randomness valuable to the process.
It could also be useful in scientific sampling for multiple reasons --- first, science should be able to withstand review, and sampling data based on a randomness beacon would ensure that others could later reproduce those results, and remove doubt that the scientists had been cherry-picking samples.
A similar use case could be the proof-of-stake consensus algorithms used in certain blockchains.
At regular intervals, they elect a leader to mint the next block of transactions, which carries a monetary reward from each transaction to the leader.
This provides an incentive to use a public source of randomness such as a beacon, to prevent malicious users from biasing the leader election process.

\subsubsection{Lotteries}
Another use case that seems natural for randomness is lotteries, that need to randomly award some prize to a participant. However, one should consider that in most cases, participants still need to trust whatever party is hosting the lottery to pay out the prize. Essentially, it does not matter whether the randomness could be biased against you, if it impossible to win at all.
In addition, the average person participating in a lottery is not necessarily critical of the randomness as their stake in the lottery is quite small.
Despite this, randomness beacons could see some use in online lotteries run by smart contracts, as they do not have any central authority that must be trusted.

\subsubsection{Cryptography}
Cryptography also contains good use cases, namely parameter generation and protocol bootstrapping.
Many cryptographic protocols require some parameters to initialize.
Choosing these can be a lengthy process~\cite{mpcsnarks}, but also requires a great deal of trust as they could contain backdoors~\cite{nist2014backdoor}.
A randomness beacon could be used to seed the pseudo-random generation of good parameters, to trustlessly generate good parameters for such protocols~\cite{baigneres2015trap}.

An excellent use case is bootstrapping for \gls{zksnark} systems. Such systems require a \emph{common reference string} that must be generated as part of the bootstrapping process. Generating this string can be an extremely complicated process, as the trust of the entire system rests on the string. Should any party possess the numbers from which the string was generated, they can effectively fake proofs of anything, undermining the system. Due to its complexity, it can be hard to scale such a process, which in turn requires more users to trust the participants. Using a randomness beacon can allow the process to scale far beyond the norm, as demonstrated by~\citet{mpcsnarks}. This not only makes it possible for more users to contribute to the system, which reduces the burden of trust on each participant, but also makes it easier to scale.

\subsubsection{Challenge-Response Protocols}
It has also previously been suggested to use randomness beacons to improve challenge-response protocols, that could be reduced to single-message protocols if both parties could access the beacon.
\citet{fischer2011publicrandomnessservice} suggest using a randomness beacon to improve a smart card challenge response protocol, which could be reduced to a single message and would be immune to chosen ciphertext attacks. However, this would necessitate that either the card could access the internet by itself, or that it was capable of verifying that a random number came from the beacon. This in turn would likely require some form of signature from the beacon the card would verify, in which case it might as well just use that algorithm for the challenge-response protocol. %This part seems weak and/or negative, consider removing ?


%In which environments are beacons suitable? Users of the beacon output may be considered private individuals, scientists, companies, and corporations.

%As a side note, all examples of use cases mentioned in this section also work with a trust-requiring beacon, \emph{if} it is reasonable to assume users are willing to trust the beacon.

%While we like the concept a randomness beacon offers (a tool to remove trust), we struggle to follow many of the use cases proposed in the literature. Classic use cases include

%\mtjnote{Write about zk-snarks}

%This recent literature presents some promising ways of creating an unbiasable beacon. However, there still exists no \enquote{killer} \enquote{real-life} use cases of a randomness beacon.
%We see many potential use cases, and present a variety of them with roots in the literature, before constructing a beacon of our own and performing a security analysis on it.

\subsection{Beacon Definition}

A randomness beacon emits an unpredictable random value at a regular interval, e.g.\ every five minutes. \cref{fig:abstract_beacon} shows the operation of an abstract beacon.
\subimport{}{simple_beacon_fig.tex}
\mtjnote{We should probably write more here?}

A beacon can further be seen as following specific models describing behavior. Here, we distinguish between an input source model and operational model. The input source model describes the way the beacon sources its input, and the operational model describes the design of the protocol, i.e.\ how to perform the computation and publish the output. These models are based on our earlier work \fxnote{Insert reference to own work previous semester?}.

\subsubsection{Input Source Models}
It is important that the user can trust the input to not be biased in such a way that it negatively affects the output. We therefore see three approaches to sourcing the input:

\paragraph{Private Input Sources} A beacon can use some private source of data to to produce randomness. This allows them to obtain produce randomness of high quality at a high rate, but requires users of the beacon to trust the beacon and its randomness.
As we argued, true randomness as input cannot be trusted in our setting, since it cannot reliably be distinguished from carefully crafted values that appear to be random.
An example of this is the \gls{nist}~\cite{nistbeacon} randomness beacon that observes quantum mechanical effects to produce high-quality randomness.
Ultimately it requires trust, since the observations cannot be repeated, and therefore users cannot make sure that the value is indeed from observing the quantum mechanical effect.
As such, the users need to blindly trust the beacon operator, which in the case of \gls{nist} can be hard given their history~\cite{nytimes-nsabackdoors, nytimes-nsaconstants, nist2014backdoor}.

%Fortunately, the vast majority of use cases do not actually require true randomness.
%Far more desirable is the side effect of producing randomness: \emph{unpredictability}.
%As long as the output is unpredictable for all parties including the beacon operator, we do not really need true randomness, and the beacon output can be produced by a deterministic algorithm.
%And if implemented correctly, deterministic pseudo-randomness is just as good for virtually all use cases and provides a good level of unpredictability.
%No true randomness is necessary but we care deeply about the unpredictability from deterministic pseudo-randomness.

\paragraph{Publicly Available Sources} Using a publicly available source that everyone can agree on the value of, such as bitcoin transaction hashes, stock market data or lottery winning numbers from several international lotteries.
The user must trust the source, and this is reasonable because these sources are governed by some guarantees. E.g.\ in case of bitcoin, the transaction hashes have a monetary value and they are hard to pre-image. The rate of the source also dictates that of the beacon which can be an issue for some use cases. Users will also have to interact with the source to indirectly influence the beacon and prevent collusion. However, it may also be harder for colluding adversaries to bias the beacon through the source unless they are in complete control of it.

\paragraph{User Input}
A user can be allowed to directly provide input to the computation.
The idea is that a user provides a value that they firmly believe is so random that all other users cannot reasonably generate the same value.
The beacon then performs an operation on a set of user-supplied input, where each input is a value that a specific user believes is a sufficiently random. The output of the beacon is structured in a way that
\begin{eletterate*}
    \item allows all users to verify the inclusion of their value and
    \item allows all users to verify the validity of the computation.
\end{eletterate*}

If these are satisfied, the user knows that a value they trust to be random has been part of the random output generation. The computation performed by the beacon should ensure that users cannot knowingly bias the output to anyone's disadvantage. As such, the user knows that his input was not knowingly \enquote{counteracted} by another used.

\subsubsection{Operational Models}
We identify three ways in which a beacon is typically operated:

\paragraph{Autocratic Collector} A beacon is run by a party, which deems it irrelevant to prove honesty. Instead, they require users to trust them to do what they say. As such, the computation will be a black box with no possibility for proof of honesty. This type always lies in the trust-requiring category of beacons.

\paragraph{Specialized \acrshort{mpc}} Users utilize \acrfull{mpc} to collectively produce randomness, typically from their own inputs. Given an honest majority, this type of beacon produces randomness that is not biased against the participants, and although work has been done in the field, they are difficult to scale to large groups~\cite{cascudo2017scrape, syta2017scalable}.

\paragraph{Transparent Authority} A single entity collects input and publishes it with a focus on transparency. Users can by observing the beacon verify that the beacon behaves according to protocol. This does not directly prevent byzantine behavior, but rather makes it difficult or nearly impossible to hide such behavior. This type also support a wide variety of implementations, and is scalable to a public setting.

\subsection{Delimitations}%
\label{sub:delimitations}
We want to create a randomness beacon that is secure under the assumption that everyone may be colluding against a given user, as per our security goals in \cref{sec:security_goals}. As such, we can immediately see that the autocratic collector is not suitable for our security goal, because it requires users to trust its hopefully honest operation. The \gls{mpc} model does not scale well enough for general use. Further, this model assumes an honest majority, which is a weaker assumption than our security goals. Therefore, it will not be suitable for us. This leaves us with the transparent authority model, which we adopt.

Regarding input source models, we can immediately discard private input sources. They are tied to the autocratic collector model, and as such do not work for the transparent authority. The guarantees by publicly available sources are weak compared to user input. If sufficiently paranoid, the user will want to bias these publicly available sources to make sure all other users are not colluding. Therefore, user input is the simplest solution and provides the strongest guarantees for the user.

\subsection{Contributions}
We bridge the gap between the literature and the real world by designing and implementing a secure, trust-minimizing randomness beacon based on the transparent authority model with user input. To this end, we conduct a structured analysis of the threats to a randomness beacon and design a beacon to mitigate as many of these as possible. We discuss the trust assumptions for use of the beacon, implement the beacon, and provide an actionable guide for when an output should be trusted. We implement the beacon, while discussing the implementations fit to the design. Finally we evaluate the security of the implementation to estimate how well it measures up the design.
%Last line is bogus, we havent evaluated yet.
