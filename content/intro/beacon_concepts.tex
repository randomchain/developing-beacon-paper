\subsection{Beacon Concepts}

A randomness beacon emits an unpredictable random value at a regular interval, e.g.\ every five minutes.
\cref{fig:abstract_beacon} shows the workings of a simple, generic beacon.
The beacon performs \emph{some} computation on an input source in order to generate an unpredictable number.
The result of this computation is sent to users.
This workflow is repeated indefinitely at the specified interval.
\subimport{}{simple_beacon_fig.tex}

Examining existing beacons~\cite{nistbeacon,randomzoo,bentov2016bitcoin,fischer2011publicrandomnessservice,bonneau2015bitcoin,baigneres2015trap,clark2010use,randao,bunz2017proofsof,syta2017scalable,cascudo2017scrape}, a few common ways of composing the input sourcing and computation are discernible and can be described as specific models.
Here, we distinguish between an input source model and operational model.
The input source model describes the way the beacon sources its input, while the operational model describes the design of the protocol, i.e.\ how to perform the computation and publish the output.
These models are based on our earlier work~\cite{worldsbestpaper}, a survey of different approaches to randomness beacons as presented in literature.

\subsubsection{Input Source Models}
Based on a survey of randomness beacons we made in previous work~\cite{worldsbestpaper}, there are three sources of input:

\paragraph{Private Input Sources}
A beacon can use a private source of data to produce randomness.
This allows them to produce randomness of high quality at a high rate, but since users are seldom present to physically inspect this private source, it requires users of the beacon to trust the beacon and its randomness.
This does not align well with our aforementioned security goals, since inputs cannot reliably be distinguished from carefully crafted values that appear to be random.
An example of this input source model is the \gls{nist} randomness beacon~\cite{nistbeacon} which observes quantum mechanical effects to produce what they claim is high-quality randomness.
Ultimately it requires trust, since the observations cannot be repeated, and therefore users cannot make sure that the value is indeed from observing the quantum mechanical effects.
As such, the users need to blindly trust the beacon operator, which in the case of \gls{nist} can be hard given their history~\cite{nist2014backdoor, nytimes-nsaconstants, nytimes-nsabackdoors}.

\paragraph{Publicly Available Sources}
This input source model uses publicly available sources that everyone can agree on the value of, such as bitcoin blocks, stock market data, or lottery winning numbers from several international lotteries.
The user must trust the source, and this is reasonable since these sources are governed by some guarantees, and often it is easy to see the freshness of these values.
In case of bitcoin, the blocks have a monetary value and are virtually impossible to forge.
Users have to interact with the source to indirectly influence the beacon and prevent biased outputs.
However, it may also be harder for adversaries to bias the beacon through the source unless they are in complete control of the given source.

\paragraph{User Input}
A user can be allowed to directly provide input to the beacon.
The idea is that a user provides a value that they firmly believe is sufficiently random, such that nobody could have predicted the value.
In other words, users know their own value is fresh, and no other party could realistically have used this value before.
There exists no concept of ownership of specific values, which means that users should trust the input they give, and not the fact that it is their own.
However, for the sake of simplicity we, throughout this paper, refer to an input trusted by a given user to be said user's input.

The beacon performs an operation on a set of user-supplied inputs.
The output of the beacon is structured in a way that
\begin{eletterate*}
    \item allows all users to verify the inclusion of their input and
    \item allows all users to verify the validity of the computation.
\end{eletterate*}

If these are satisfied, the user knows that a value they trust to be random has been part of the random output generation.
The computation performed by the beacon should ensure that users cannot knowingly bias the output to anyone's disadvantage.
As such, the user knows that his input was not knowingly \enquote{counteracted} by another used.

\subsubsection{Operational Models}
Alongside presenting input source models in our previous work~\cite{worldsbestpaper}, we also identify three ways in which a beacon is typically operated:

\paragraph{Autocratic Collector}
A beacon is run by a party, which deems it irrelevant to prove honesty, thus requiring blind trust from the users.
As such, the computation is a black box with no possibility for proof of honesty.
This type lies in the trust-requiring category of beacons, i.e.\ the old generation.

\paragraph{Specialized \acrshort{mpc}}
Users utilize \acrfull{mpc} to collectively produce randomness, typically from their own inputs.
Given an honest majority, this type of beacon produces randomness that is not biased against the participants, and although work has been done in the field, they are difficult to scale to large groups since any addition or removal of a user requires a new setup phase~\cite{cascudo2017scrape, syta2017scalable}.
This type of beacon is therefore unsuited for public settings, but might fit in a controlled private context.

In \vref{sub:drand_a_distributed_randomness_beacon_daemon} we describe the state of the art of specialized \gls{mpc} randomness beacons.

\paragraph{Transparent Authority}
A single entity collects input and publishes it with a focus on transparency.
Users can, by observing the beacon, verify that it behaves according to protocol.
This does not directly prevent byzantine behavior, but rather makes it difficult or nearly impossible to hide such behavior.
This type also support a wide variety of implementations, and is potentially scalable to a public setting.
