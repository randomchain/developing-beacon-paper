\subsection{Delimitations}%
\label{sub:delimitations}
We want to create a randomness beacon that is secure under the assumption that everyone may be colluding against a given user, as per our security goals in \cref{sec:security_goals}.
As such, we can immediately see that the autocratic collector is not suitable for our security goal, because it requires users to trust its claimed honest operation.
The \gls{mpc} model does not scale well enough for general use in public randomness beacons~\cite{syta2017scalable}.
As described by \citet{damgaard2006scalable}, \gls{mpc} protocols either assumes an honest majority, which is a weaker assumption than our security goals, or cannot guarantee fairness and output delivery, a likewise undesired behavior.
Even as more scalable \gls{mpc} protocols has been developed, they still need some assumptions about the protocol participants, which we cannot guarantee in a public randomness beacon.
An example of this is the \gls{mpc} protocol designed by \citet{damgaard2006scalable}, which they claim is the first scalable general \gls{mpc} protocol.
This protocol still only allows for corruption of some constant fraction of the participants, and furthermore assumes the existence of a computationally simple pseudorandom generator to maintain a constant number of rounds needed to complete the protocol.

Since our world view of \enquote{everybody is colluding against you} is far more pessimistic than the guarantees provided by the aforementioned protocols, \gls{mpc} is not suitable for us, although the model could fit in a more controlled or private environment.
This leaves us with the transparent authority model which we adopt.
This choice adds a role to our environment: the beacon operator.
Our security goal of everybody colluding against a user must therefore be expanded such that \emph{everybody} includes the beacon operator.

Regarding input source models, we can immediately discard private input sources as they are tied to the autocratic collector model, and as such do not work for the transparent authority.
The guarantees by publicly available sources are weak compared to user input.
If sufficiently paranoid, the user will want to bias these publicly available sources to make sure all other users are not colluding.
Therefore, user input is the simplest solution and provides the strongest guarantees for the user.

