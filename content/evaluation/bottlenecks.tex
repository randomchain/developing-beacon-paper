\subsection{Bottlenecks}%
\label{sub:bottlenecks}
We examine two potential bottlenecks in our beacon.
These are components which require the most effort to scale horizontally, and as such for simplicity we want to discover the current limits before scaling.
Furthermore, it is important to determine if these are actual bottlenecks before attempting to scale, as we want to avoid premature optimization.

\subsubsection{Proxies}%
\label{ssub:proxies}
As presented in \vref{sub:infrastructure}, our beacon contains two proxies.
We believe that the \textit{forward} proxy between computation and publishers never will be a bottleneck in a real world randomness beacon deployment, as the data passing through it only consists of outputs, commitments, and proofs.
However, the \textit{stream} proxy situated between input collectors and input processors must be equipped to handle a constant stream of input messages.

As previously mentioned, this proxy facilitates fan-in and fan-out pipelining with fair message distribution using a round-robin strategy.
Hence, we test the throughput of the proxy in different configurations of input collectors and input processors.
For simplicity and benchmark consistency, we utilize \enquote{dummy} components for this.
The input collectors are referred to as \textit{pushers} and fan in at the proxy, while the input processors are called \textit{pullers} and fan out.
In the tests we transmit messages which resemble those of an actual beacon in size, i.e.\ 64 bytes of application data plus any \textit{ZeroMQ} packaging; in this case one byte which serves as a flags field, and one byte to denote the length of the message body\footnote{As per the framing specification in \url{https://rfc.zeromq.org/spec:23/ZMTP}}.

In \vref{fig:proxy_throughput} we see how the aforementioned different configurations affect the throughput of messages in the proxy.
Firstly, no configuration combination measured results in a throughput below circa 200,000 messages per second.
We presume this is significantly higher than the number of inputs a real world beacon would ever be constantly subjected to --- as this also would cause significant problems further down the pipeline, e.g.\ the sheer amount of data contained in a commitment.

It is the scenario of one pusher to sixteen pullers that results in the lowest throughput, which can be caused by the overhead of the fair message distribution enforcement.
However, as we add pushers at sixteen pullers, a slight increase in throughput can be seen, suggesting that fair distribution is easier with more suppliers.

Another observation we can make from \cref{fig:proxy_throughput} is that increasing the number of pushers does not affect the throughput as much as adding pullers does.
This evinces that fan-out is a considerably more expensive task than fan-in --- a fortunate fact, since a deployment of our beacon most likely will consist of remarkably more pushers than pullers.

We can conclude that the proxies in our system are extremely unlikely to be bottlenecks, and we should rather look further down the pipeline for issues; hence we examine the input processor.

\begin{figure}[tb]
    \centering
    \footnotesize
    \begin{tikzpicture}
        \begin{axis} [%
            width=0.95\columnwidth,
            xlabel=pullers,
            xtick={1,4,8,12,16},
            ylabel=pushers,
            ytick={1,4,8,12,16},
            zlabel=throughput (messages/s),
            zlabel shift=-6pt,
            grid=major]
            \addplot3+ [
                surf,
                mesh/rows=5,
                mesh/ordering=colwise,
                opacity=.7,
                scatter,
                shader=faceted,
                ] table [
                y={PUSHERS},
                x={PULLERS},
                z={THROUGHPUT},
                col sep=comma
                ] {plotdata/proxydata.csv};
        \end{axis}
    \end{tikzpicture}
    \caption{%
        64 bytes message throughput per second of \textit{stream} proxy, with different numbers of pullers and pushers.
Overhead of round-robin message distribution can be seen affecting throughput.}%
\label{fig:proxy_throughput}
\end{figure}
\begin{figure}[tb]
    \centering\footnotesize
    \begin{tikzpicture}
        \begin{axis} [
            width=\axisdefaultwidth,
            height=5.7cm,
            xlabel=number of leaves,
            ylabel=time (s),
            legend pos=north west,
            ymajorgrids=true,
            xmajorgrids=true,
            major tick length=0pt
            ]
            \addplot [only marks, mark=*, mark size=1, color=GoogleBlue] table [col sep=comma, x index=0, y index=1] {plotdata/merkledata2.csv};
            \addplot [no markers, color=GoogleBlue] table [col sep=comma, x index=0, y={create col/linear regression={y=BUILD}}] {plotdata/merkledata2.csv};
            \addlegendentry{%
        $\pgfmathprintnumber{\pgfplotstableregressiona} \cdot x
        \pgfmathprintnumber[print sign]{\pgfplotstableregressionb}$}
        \end{axis}
    \end{tikzpicture}
    \caption{Correlation between number of leaves and the time it takes to build a Merkle tree, with those leaves.}%
\label{fig:merkle_build}
\end{figure}
\subimport{}{figures.tex}
\subsubsection{Input Processor --- Building Merkle Trees}%
\label{ssub:input_processor_building_merkle_trees}
The most expensive task performed in a bottleneck is building the Merkle tree in our input processor.
This task is done periodically when it is time to compute a new random output.
It should not take a significant amount of time, since this would extend the time between the last seen input and publishing the commit.
As such, we examine how the number of leaves, i.e.\ inputs, affects the building time of the Merkle tree.

In \cref{fig:merkle_build}, a linear growth in build time is seen as a factor of the number of leaves.
The growth is slow and is negligible in our beacon.
There needs to be well over 2 million leaves to result in a build time over three seconds.
We can describe the relationship as follows, where $N$ is the number of leaves:
$$
1.41\,\mu\text{s} \cdot N + 1.41\,\text{ms}
$$

Admittedly, the build time could be a problem if significantly many inputs are used.
However, in this case one might reimplement the input processor in a more performant language than Python, e.g.\ C.
In addition, the construction of Merkle trees is trivially parallelized.
Our implementation of Merkle trees does not take advantage of this fact, and so building subtrees in multiple processes and merging them to form the final tree will likely provide a significant speed-up with a factor close to the number of available CPU cores.