\subsection{Bottlenecks}%
\label{sub:bottlenecks}

We examine two potential bottlenecks in our beacon.
These are components which require the most effort to scale horizontally, and as such for simplicity we want to discover the current limits before scaling.
Furthermore, it is important to determine if these are actual bottlenecks before attempting to scale, as we want to avoid premature optimizations.

\subsubsection{Proxies}%
\label{ssub:proxies}
As presented in \vref{sub:infrastructure}, our beacon contains two proxies.
We firmly believe that the \textit{forward} proxy between computation and publishers never will be a bottleneck in a real world randomness beacon deployment.
However the \textit{stream} proxy situated between input collectors and input processors, must be equipped to handle a constant stream of messages, as inputs are submitted to the beacon.

As previously mentioned this proxy facilitates fan-in and fan-out pipelining with fair message distribution using a round-robin strategy.
Hence we test the throughput of the proxy in different configurations of input collectors and input processors.
For simplicity and benchmark consistency, we utilize \enquote{dummy} components for this.
The input collectors are referred to as \textit{pushers} and fan-in at the proxy, while the input processors are called \textit{pullers} and fan-out.
In the tests we transmit messages which resembles those of an actual beacon in size, i.e.\ 64 bytes of application data plus any \textit{ZeroMQ} packaging \msmnote{find out how much Ã¸mq actually adds}.

In \vref{fig:proxy_throughput} we see how the aforementioned different configurations affect the throughput of messages in the proxy.
Firstly, no configuration results on a throughput below circa 200,000 messages per second.
We suspect this to be significantly higher than the number of inputs a real world beacon would ever be constantly subjected to --- as this also would cause significant problems further down the pipeline.

It is the scenario of one \textit{pusher} to sixteen \textit{pullers}, which results in the lowest throughput, which can be caused by the overhead of the fair message distribution enforcement.
However, as we add \textit{pushers} at sixteen \textit{pullers}, a slight increase in throughput can be seen, suggesting that designation of certain \textit{pushers} to \textit{pullers} can alleviate some internal computations.

Another observation we can make from \cref{fig:proxy_throughput}, is that increasing the number of \textit{pushers} does not affect the throughput as adding \textit{pullers} does.
This evinces that fan-out, is a considerably more expensive task than fan-in --- a fortunate fact, since a deployment of our beacon most likely will consist of remarkably more \textit{pushers} than \textit{pullers}.

We can conclude that the proxies in our system are extremely unlikely to be bottlenecks, and we should rather look further down the pipeline for issue; hence we examine the input processor.

\begin{figure}
    \centering
    \footnotesize
    \begin{tikzpicture}
        \begin{axis} [%
            width=0.95\columnwidth,
            xlabel=pullers,
            xtick={1,4,8,12,16},
            ylabel=pushers,
            ytick={1,4,8,12,16},
            zlabel=throughput (messages/s),
            zlabel shift=-6pt,
            grid=major]
            \addplot3+ [
                surf,
                mesh/rows=5,
                mesh/ordering=colwise,
                opacity=.7,
                scatter,
                shader=faceted,
                ] table [
                y={PUSHERS},
                x={PULLERS},
                z={THROUGHPUT},
                col sep=comma
                ] {plotdata/proxydata.csv};
        \end{axis}
    \end{tikzpicture}
    \caption{%
        64 bytes message throughput per second of \textit{stream} proxy, with different numbers of pullers and pushers.
Overhead of round-robin message distribution can be seen effecting throughput.}%
    \label{fig:proxy_throughput}
\end{figure}

\subsubsection{Input Processor --- Building Merkle Trees}%
\label{ssub:input_processor_building_merkle_trees}
The most expensive task performed in a bottleneck, is building the Merkle tree in our input processor.
This task is done periodically when it is time to compute a new random output.
It should not take a significant amount of time, since this would extend the time between the last seen input and publishing the commit.
As such, we examine how the number of leaves, i.e.\ inputs, relates to the time it takes to build the Merkle tree.

In \cref{fig:merkle_build}, a linear growth in build time is seen as a factor of the number of leaves.
The growth is slow and is negligible in our beacon. There needs to be well over 2 million leaves to result in a build time over three seconds.
We can describe the relationship as follows, where $N$ is the number of leaves:
$$
1.41\,\mu\text{s} \cdot N + 1.41\,\text{ms}
$$

Admittedly, the build time could be a problem if significantly many inputs are used.
However, in this case one might reimplement the input processor in a more performant language than Python, e.g.\ C.
In addition, the construction of Merkle trees is trivially parallelized.
Our implementation of Merkle trees does not take advantage of this fact, and so building subtrees in multiple processes and merging them to form the final tree will likely provide a significant speed-up with a factor close to the number of available CPU cores.

\begin{figure}
    \centering\footnotesize
    \begin{tikzpicture}
        \begin{axis} [
            width=\axisdefaultwidth,
            height=5cm,
            xlabel=number of leaves,
            ylabel=time (s),
            legend pos=north west,
            ymajorgrids=true,
            xmajorgrids=true,
            major tick length=0pt
            ]
            \addplot [only marks, mark=*, mark size=1, color=GoogleBlue] table [col sep=comma, x index=0, y index=1] {plotdata/merkledata2.csv};
            \addplot [no markers, color=GoogleBlue] table [col sep=comma, x index=0, y={create col/linear regression={y=BUILD}}] {plotdata/merkledata2.csv};
            \addlegendentry{%
        $\pgfmathprintnumber{\pgfplotstableregressiona} \cdot x
        \pgfmathprintnumber[print sign]{\pgfplotstableregressionb}$}
        \end{axis}
    \end{tikzpicture}
    \caption{Correlation between number of leaves and the time it takes to build a Merkle tree, with those leaves.}%
    \label{fig:merkle_build}
\end{figure}
