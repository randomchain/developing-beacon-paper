\subsection{System Interface}%
\label{sub:system_interface}
As previously mentioned, the system boundaries, i.e.\ where users and the outside world interacts with the beacon, are handled by input collectors and publishers.
We implement these and the surrounding infrastructure, as well as vertical scaling if the load becomes too high on a single component.

To limit the space of potential messages and message sizes passed around inside of our system, we sanitize the user inputs by hashing them at the entry point. Realistically, allowing \emph{any} input could be seen as an invitation by some users to post messages or even files, e.g.\ illegal or inappropriate content. Our choice of hashing at entry point will mitigate this.

Given a substantial amount of users, receiving and hashing inputs may become a costly affair performance-wise.
Fortunately, the state of an input collector is only relevant to a single input request, meaning that scaling and even distributing across many machines is a trivial task.
When we hash an input, as a convenience we return the hashed input as a response. As such, they will later be able to confirm that their hashed input was used in the output of the beacon.
To allow users to verify correct hashing, the hashing algorithm should be made publicly known.

Currently we use the SHA512 hashing algorithm since its digest size is 64 bytes, which gives us reasonably sized messages flowing through the system, while still having $2^{512}$ possible different values. It could be argued that the 32 bytes of SHA256 are more than enough for any use case. However, SHA512 is actually roughly 1.5 times faster than SHA256 on a 64-bit CPU~\cite{sha512faster}. Therefore we see no reason to limit the possibilities to $2^{256}$, since we do not expect 512 bits per input to be too much data. Furthermore, truncating a SHA512 to any desired length is safe~\cite{sha512faster}.
It is important that the same hashing function is used throughout the system, since differences in output space will bias the outcome if the inputs are hashed multiple times --- which is the case.
However, we implement the system such that the chosen hashing algorithm can be configured at beacon start.

Notice that a beacon outputs twice per cycle. Before the delay function is applied, a commitment is released from the computation node and published through all publishers. Specifically, this commitment contains all leaf nodes of the Merkle tree, which corresponds to all inputs. After the delay function, the output is sent to the publishers. The output consists of two parts:
\begin{eletterate*}
    \item the result, computed from the commitment; and
    \item a witness, which can be used to rapidly verify the result.
\end{eletterate*}
The commitment and output are correlated by an arbitrary sequence number.

The publishers publish to multiple different outlets.
We implement several publishers, with different capabilities.
This means that e.g.\ a JSON publisher can dump all publishing messages, while a Twitter publisher only is able to post messages with 280 characters.
