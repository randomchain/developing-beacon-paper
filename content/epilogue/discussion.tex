\section{Discussion}%
\label{sec:discussion}
In this section we discuss some questions, which came up during our work.
This includes presenting some alternatives to our approaches, and exploring threats which we did not succeed in mitigating.

\subsection{Output Dependency}
We suggest a variety of use cases for our beacon, but we must include one important caveat: users should not critically depend on the output.

This is because we can not always guarantee that there will be an output due to the possibility of attacks on the availability.
Instead, users should aim towards being flexible with when they need to use an output.
An example could be to use the \textit{next} output that they see a timely commit containing their input to.
Only then will they be certain that the output is not biased.

\subsection{Unmitigated Threats}
We have mitigated a variety of threats to our beacon in its design, but there are still some left.
In particular, we have not focused on mitigating the threats to the availability.
This is because a variety of existing solutions for mitigating \gls{dos} attacks already exist, and that these problems are not particular to randomness beacons.

However, there are still threats to the integrity that have not been mitigated.
Man-in-the-middle attacks is one of those threats.
This is a highly damaging threat that consists of intercepting and manipulating messages between the beacon and users.
The goal is to make users use biased randomness that favors the adversary, but this requires all users to receive the manipulated randomness, which makes the attack difficult to execute.
In practice, it could likely also be mitigated by signing messages sent by the beacon to prevent them from being manipulated.
However, this brings forth a new issue of managing and more importantly trusting certificates.

Cryptography exploits is another threat we have not, and quite possibly cannot mitigate.
Our beacon uses a variety of cryptographic components like hash functions and delay functions.
If exploits were found in any of these, it would completely change the assumptions on the beacon.
If a shortcut to computing the delay function was found, it would allow adversaries to perform input manipulation attacks.

\subsection{Alternative Delay Functions}
We currently use a time-hard function to compute our randomness.
This provides us some indication of the computational effort needed to correctly produce a random number, and thus makes it harder to cheat.
However, requirements on processing power is not an insurmountable obstacle for motivated attackers.
An excellent example of this is the bitcoin blockchain, where mining consists of solving a computational puzzle by repeatedly hashing.
Here, \glspl{asic} have allowed significant speedups in the mining process, which has resulted in raised mining difficulty, and ordinary computers becoming comparatively useless for mining purposes.
If any party was to develop \glspl{asic} for our delay function, they would be able to solve it much faster than any other party.
This would diminish the security provided by the delay function, and open up for last-draw attacks from the party with the \gls{asic}.

One way to mitigate this would be to increase the difficulty of the delay function, like it has been done in bitcoin.
However, this would have the side effect of making the function much more costly to compute for any party without \glspl{asic}.
This could even include the beacon operator, which would impact operations.

Another way to mitigate this would be to use a delay function that was also memory-hard, i.e.\ required large amounts of memory to compute.
This would make it resistant to \gls{asic}-equipped adversaries, as these have small amounts of memory to optimize for speed.
While the function would require more resources, it should still be computable for an ordinary computer.

\subsection{Salting}
One thing we considered in the design of the beacon was having the operator add a salt to the inputs.
This would make the operator the only party capable of computing the output, which would prevent outsiders from pre-imaging and performing last-draw attacks without help from the operator.

On the other hand, this would give the operator even more power.
They could perform more damaging withholding attacks, as they would be the only party capable of producing the beacon output.
This could be mitigated by having the operator publish a timed commitment to the salt alongside the inputs --- this second commit could then be revealed by outsiders given enough time, which would prevent the operator from withholding once both commits were published.

\subsection{Smart Contracts}
A distrustful environment is an obvious setting for a randomness beacon, and one of the most obvious types of these are public blockchains.
We therefore find it interesting to consider implementing our beacon in a smart contract on a blockchain.

There would be some definite benefits to this, namely that it would remove the need for a single operator, which removes some threats towards the beacon.
In addition, it would be much harder to \gls{dos} attack the beacon, as it would be run by the entire network.

However, a central aspect of our beacon is practically incompatible with the nature of smart contracts, as delay functions are computationally intensive.
Smart contracts need to pay for each computation they make, which would make the beacon costly to run.

This would tie the beacon into the monetary incentive structures that dictate smart contract behavior.
Running a smart contract equivalent of our randomness beacon would be expensive due to the use of delay functions.
However, some parts, like the verification process, are nowhere near as intensive, and could potentially be implemented in a smart contract.

This has also been examined in the literature, where \citet{bunz2017proofsof} implement an Ethereum smart contract to publish and challenge the output of their beacon.
We described the relation of their work to our in \vref{ssub:proofs_of_delay}.
Their beacon requires money to publish outputs on the blockchain, and users must pay to challenge a given output.
They also provide a detailed analysis of the incentives the beacon should provide to ensure correct behavior.

In addition, since parts of the beacon would still be off-chain, those parts would still be dependent on an operator and vulnerable to \acrshort{dos} attacks.

Another thing to consider is that everything that occurs on a blockchain occurs because someone put it into a block.
This is typically the job of miners, who have different interests than other users.
They are incentivized to include the transactions that give the greatest rewards for the block.
Thus, a user would have to pay a competitive fee to interact with a beacon on a blockchain.

If we also consider the trust assumption of everyone being against the user, they would have to mine the block themselves to guarantee their interaction, which is a steep requirement.
\mtjnote{I thunk abot it}

